import pandas as pd
import numpy as np
from scipy.cluster.hierarchy import linkage, fcluster
from scipy.spatial.distance import squareform
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.feature_selection import mutual_info_classif, mutual_info_regression
from sklearn.exceptions import NotFittedError
from joblib import Parallel, delayed

class VIFReducerSmartAdaptive(BaseEstimator, TransformerMixin):
    def __init__(self, vif_threshold=5.0, initial_corr=0.99, min_corr=0.5, max_iter=30,
                 n_jobs=-1, problem_type='auto', verbose=True):
        self.vif_threshold = vif_threshold
        self.initial_corr = initial_corr
        self.min_corr = min_corr
        self.max_iter = max_iter
        self.n_jobs = n_jobs
        self.problem_type = problem_type
        self.verbose = verbose
        self.selected_features_ = None
        self.history_ = []

    def _check_dataframe(self, X):
        if isinstance(X, pd.DataFrame):
            return X.copy()
        else:
            X = pd.DataFrame(X)
            X.columns = [f"Var{i}" for i in range(X.shape[1])]
            return X

    def _remove_constant_features(self, X):
        nunique = X.nunique()
        constant_cols = nunique[nunique <= 1].index.tolist()
        if constant_cols and self.verbose:
            print(f"Removing constant features: {constant_cols}")
        return X.drop(columns=constant_cols)

    def _calculate_vif_parallel(self, X, feature_names):
        def compute_vif_col(X, i):
            try:
                return variance_inflation_factor(X, i)
            except Exception:
                return np.inf

        vifs = Parallel(n_jobs=self.n_jobs)(
            delayed(compute_vif_col)(X, i) for i in range(X.shape[1])
        )
        vif_data = pd.DataFrame({'feature': feature_names, 'VIF': vifs})
        return vif_data

    def _cluster_features(self, df, corr_threshold, y=None):
        corr = df.corr().abs()
        dist = 1 - corr
        dist_array = squareform(dist, checks=False)
        linkage_matrix = linkage(dist_array, method='average')
        cluster_labels = fcluster(linkage_matrix, t=1-corr_threshold, criterion='distance')

        selected_features = []
        cluster_mapping = {}

        for cluster in np.unique(cluster_labels):
            cluster_features = df.columns[cluster_labels == cluster].tolist()
            cluster_mapping[cluster] = cluster_features

            if len(cluster_features) == 1:
                selected_features.append(cluster_features[0])
            else:
                sub_corr = corr.loc[cluster_features, cluster_features]
                mean_corr = sub_corr.mean()
                candidate = mean_corr.idxmin()

                if y is not None:
                    if self._is_classification:
                        mi = mutual_info_classif(df[cluster_features], y, random_state=42)
                    else:
                        mi = mutual_info_regression(df[cluster_features], y, random_state=42)
                    mi_series = pd.Series(mi, index=cluster_features)
                    candidate = mi_series.idxmax()

                selected_features.append(candidate)

        return selected_features, cluster_mapping

    def fit(self, X, y=None):
        X = self._check_dataframe(X)
        X = X.select_dtypes(include=[np.number])
        X = self._remove_constant_features(X)
        self.feature_names_all_ = X.columns.tolist()

        if self.problem_type == 'auto':
            self._is_classification = True if y is not None and (pd.Series(y).nunique() < 20) else False
        elif self.problem_type == 'classification':
            self._is_classification = True
        else:
            self._is_classification = False

        corr_threshold = self.initial_corr
        best_features = self.feature_names_all_
        self.history_ = []

        for i in range(self.max_iter):

            vif_full = self._calculate_vif_parallel(X.values, X.columns)
            max_vif_full = vif_full['VIF'].replace(np.inf, 1e10).max()

            selected, cluster_mapping = self._cluster_features(X, corr_threshold, y=y)
            reduced_df = X[selected].values
            vif_reduced = self._calculate_vif_parallel(reduced_df, selected)
            max_vif_reduced = vif_reduced['VIF'].replace(np.inf, 1e10).max()

            self.history_.append({
                'iter': i+1,
                'corr_threshold': round(corr_threshold, 4),
                'num_features': len(selected),
                'pre_cluster_vif': round(max_vif_full, 4),
                'post_cluster_vif': round(max_vif_reduced, 4),
                'selected_features': selected,
                'clusters': cluster_mapping
            })

            if self.verbose:
                print(f"Iter {i+1}: corr={corr_threshold:.3f} | pre-VIF={max_vif_full:.2f} | post-VIF={max_vif_reduced:.2f} | features={len(selected)}")

            if max_vif_reduced < self.vif_threshold:
                best_features = selected
                break

            # dynamic adjustment
            delta = min(0.05, (max_vif_reduced - self.vif_threshold)/20)
            corr_threshold = max(self.min_corr, corr_threshold - delta)

        self.selected_features_ = best_features
        return self

    def transform(self, X):
        if self.selected_features_ is None:
            raise NotFittedError("This instance is not fitted yet.")
        X = self._check_dataframe(X)
        return X[self.selected_features_]

    def fit_transform(self, X, y=None):
        return self.fit(X, y).transform(X)

    def report(self):
        return pd.DataFrame(self.history_)
    

def generate_test_dataset(n_samples=1000, seed=42):
    np.random.seed(seed)
    X1 = np.random.randn(n_samples)
    X2 = X1 * 0.95 + np.random.randn(n_samples) * 0.05
    X3 = np.random.randn(n_samples)
    X4 = X3 * 0.85 + np.random.randn(n_samples) * 0.15
    X5 = np.random.randn(n_samples)
    X6 = X5 * 0.90 + np.random.randn(n_samples) * 0.1
    X7 = np.random.randn(n_samples)
    X8 = np.full(n_samples, 3.14)  # constant feature
    X9 = np.random.randn(n_samples)
    X10 = X9 * 0.9 + np.random.randn(n_samples) * 0.1

    y_regression = 3*X1 - 2*X3 + 1.5*X5 + np.random.randn(n_samples)*0.5
    y_classification = (y_regression > y_regression.mean()).astype(int)

    df = pd.DataFrame({
        'X1': X1, 'X2': X2, 'X3': X3, 'X4': X4, 'X5': X5, 
        'X6': X6, 'X7': X7, 'X8': X8, 'X9': X9, 'X10': X10
    })

    return df, y_regression, y_classification

df, y_reg, y_class = generate_test_dataset()

reducer = VIFReducerSmartAdaptive(vif_threshold=5.0, problem_type='regression', verbose=True)
X_reduced = reducer.fit_transform(df, y_reg)

report_df = reducer.report()
report_df
