方法	發表年份	GitHub 連結 (⭐星數 / 最後更新)	核心原理/特點	適用場景	分類標籤
SHAP	2017	shap (⭐13k+ / 2023-10)	基於博弈論的 Shapley 值，量化特徵對預測的全局和局部貢獻，模型無關。	解釋特徵重要性（分類/回歸）、對比樣本預測差異。	全局/局部、模型無關
LIME	2016	lime (⭐10k+ / 2023-09)	通過局部線性模型近似複雜模型的行為，生成針對單樣本的解釋。	解釋單個樣本預測（如文本/圖像分類）。	局部、模型無關
Partial Dependence Plots	2001	scikit-learn (⭐55k+ / 2023-10)	分析一個或多個特徵對模型預測的邊際效應，顯示全局趨勢。	理解特徵與目標變量的非線性關係（如收入預測中年齡的影響）。	全局、模型無關
Counterfactual Explanations	2019	alibi (⭐2k+ / 2023-09)	生成「反事實樣本」，展示如何修改輸入以改變預測結果。	提供可操作的改進建議（如貸款拒批後調整哪些特徵可獲批准）。	局部、模型無關
Integrated Gradients	2017	captum (⭐4k+ / 2023-10)	計算輸入特徵相對於基準值的積分梯度，適用於深度學習模型。	解釋神經網絡的特徵重要性（如圖像分類中的關鍵像素）。	局部、深度學習專用
Anchors	2018	anchor (⭐900+ / 2022-08)	生成高置信度的「規則」解釋（如「只要滿足條件A，預測結果必定為B」）。	生成人類可理解的決策規則（如醫療診斷中的關鍵指標）。	局部、模型無關
Saliency Maps	2013	tf-explain (⭐1k+ / 2023-05)	通過梯度或激活圖可視化輸入中對預測最重要的區域。	解釋視覺模型的關注點（如目標檢測中的物體定位）。	局部、深度學習專用
Global Surrogate Models	1999	interpret (⭐5k+ / 2023-09)	用簡單模型（如線性模型、決策樹）近似複雜模型的全局行為。	通過透明模型解釋黑箱模型的整體邏輯。	全局、模型無關
TCAV	2018	tcav (⭐1k+ / 2023-06)	通過「概念激活向量」量化模型對抽象概念（如「條紋」「顏色」）的依賴程度。	驗證模型是否使用特定概念進行預測（如醫學影像中的病變特徵識別）。	全局/局部、深度學習專用
ProtoDash	2018	interpret (⭐5k+ / 2023-09)	基於原型樣本（代表性樣本）解釋模型預測，類比相似案例。	通過相似樣本對比解釋預測（如「此患者與歷史病例X相似，因此診斷為Y」）。	局部、模型無關


方法	GitHub 星数	更新时间	推荐网页	核心原理/特点	适用场景	分类标签
SHAP	13k+	2023-10	shap	基于博弈论的 Shapley 值，量化特征对预测的全局和局部贡献，模型无关。	解释特征重要性（分类/回归）、对比样本预测差异。	全局/局部、模型无关
LIME	10k+	2023-09	lime	通过局部线性模型近似复杂模型的行为，生成针对单样本的解释。	解释单个样本预测（如文本/图像分类）。	局部、模型无关
Partial Dependence Plots (PDP)	55k+	2023-10	scikit-learn	分析一个或多个特征对模型预测的边际效应，显示全局趋势。	理解特征与目标变量的非线性关系（如收入预测中年龄的影响）。	全局、模型无关
Counterfactual Explanations	2k+	2023-09	alibi	生成「反事实样本」，展示如何修改输入以改变预测结果。	提供可操作的改进建议（如贷款拒批后调整哪些特征可获批准）。	局部、模型无关
Integrated Gradients	4k+	2023-10	captum	计算输入特征相对于基准值的积分梯度，适用于深度学习模型。	解释神经网络的特征重要性（如图像分类中的关键像素）。	局部、深度学习专用
Anchors	900+	2022-08	anchor	生成高置信度的「规则」解释（如「只要满足条件A，预测结果必定为B」）。	生成人类可理解的决策规则（如医疗诊断中的关键指标）。	局部、模型无关
Saliency Maps	1k+	2023-05	tf-explain	通过梯度生成显著图解释深度学习模型的预测。	解释视觉模型的关注点（如目标检测中的物体定位）。	局部、深度学习专用
Global Surrogate Models	5k+	2023-09	interpret	用简单模型（如线性模型、决策树）近似复杂模型的全局行为。	通过简单模型解释复杂模型的行为。	全局、模型无关
Explainable Boosting Machines (EBM)	5k+	2023-09	interpret	通过可加性模型提供可解释性。	在保持高精度的同时提供可解释性。	全局、模型无关
RuleFit	1k+	2022-08	rulefit	结合规则和线性模型解释复杂模型。	生成规则解释模型预测。	全局、模型无关
推荐网页说明
GitHub 星数与更新时间：数据截至 2023 年 10 月，星数标记为近似值（如 1k = 1000+），实际数据可能略有浮动。

推荐网页：优先选择 GitHub 官方仓库或相关技术博客，确保信息准确性和权威性。

分类标签：

全局解释：针对整个模型的行为进行解释（如 SHAP 全局解释、PDP）。

局部解释：针对单个样本的预测进行解释（如 LIME、SHAP 局部解释）。

模型无关：适用于任何机器学习模型（如 LIME、SHAP）。

深度学习专用：主要用于深度学习模型（如 Integrated Gradients、Saliency Maps）。

如何选择方法？
需要全局理解：优先选择 SHAP（全局）、PDP、Global Surrogate Models。

解释单样本决策：使用 LIME、Counterfactual Explanations、Anchors。

深度学习模型：尝试 Integrated Gradients、Saliency Maps。

生成可操作建议：Counterfactual Explanations、Anchors。
