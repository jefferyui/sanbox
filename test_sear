import pandas as pd
import numpy as np
from geneticalgorithm import geneticalgorithm as ga

# 創建測試資料
np.random.seed(42)  # 固定隨機種子以便重現
data = {
    'weight': np.random.choice(['w1', 'w2', 'w3'], size=100),  # 隨機選擇 w1, w2, w3
    'score': np.random.rand(100)  # 隨機生成 0 到 1 的分數
}

df = pd.DataFrame(data)

# One-hot 編碼 weight 欄位
df_encoded = pd.get_dummies(df['weight'], prefix='weight')
X = df_encoded.values
y = df['score'].values

# 定義目標函數
# weights 是 [w1, w2, w3]
def objective_function(weights):
    predictions = np.dot(X, weights)
    penalty = 1000 * abs(sum(weights) - 1)  # 確保 w1 + w2 + w3 = 1
    return -np.sum(predictions) + penalty  # 最大化總分轉為最小化，並加入懲罰項

# 定義邊界: 每個權重在 0 到 1 之間
varbound = np.array([[0, 1], [0, 1], [0, 1]])

# 設定基因演算法的參數
algorithm_param = {
    'max_num_iteration': 500,
    'population_size': 100,
    'mutation_probability': 0.1,
    'elit_ratio': 0.01,
    'crossover_probability': 0.5,
    'parents_portion': 0.3,
    'crossover_type': 'uniform',
    'max_iteration_without_improv': None
}

# 初始化基因演算法模型
model = ga(
    function=objective_function,
    dimension=3,
    variable_type='real',
    variable_boundaries=varbound,
    algorithm_parameters=algorithm_param
)

# 執行基因演算法
model.run()

# 最佳化結果
optimal_weights = model.output_dict['variable']
max_score = -model.output_dict['function']  # 轉回最大化的分數
print(f"Optimal weights: w1 = {optimal_weights[0]:.4f}, w2 = {optimal_weights[1]:.4f}, w3 = {optimal_weights[2]:.4f}")
print(f"Maximum weighted score: {max_score:.4f}")




###############3

import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# 創建測試資料
np.random.seed(42)  # 固定隨機種子以便重現
data = {
    'weight': np.random.choice(['w1', 'w2', 'w3'], size=100),  # 隨機選擇 w1, w2, w3
    'score': np.random.rand(100)  # 隨機生成 0 到 1 的分數
}

df = pd.DataFrame(data)

# One-hot 編碼 weight 欄位
df_encoded = pd.get_dummies(df['weight'], prefix='weight')
X = df_encoded.values
y = df['score'].values

# 將資料分成訓練集和測試集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 定義目標函數
# weights 是 [w1, w2, w3]
def objective_function(weights):
    train_predictions = np.dot(X_train, weights)
    test_predictions = np.dot(X_test, weights)
    
    # 多目標融合: 訓練集的 MSE + 測試集的懲罰項 (針對過度擬合)
    mse_train = mean_squared_error(y_train, train_predictions)
    mse_test_penalty = mean_squared_error(y_test, test_predictions) * 10
    
    penalty = 1000 * abs(sum(weights) - 1)  # 確保 w1 + w2 + w3 = 1
    return mse_train + mse_test_penalty + penalty  # 最小化損失

# 定義邊界: 每個權重在 0 到 1 之間
varbound = np.array([[0, 1], [0, 1], [0, 1]])

# 使用基因演算法 (GA) 的參數
from geneticalgorithm import geneticalgorithm as ga
algorithm_param = {
    'max_num_iteration': 500,
    'population_size': 100,
    'mutation_probability': 0.1,
    'elit_ratio': 0.01,
    'crossover_probability': 0.5,
    'parents_portion': 0.3,
    'crossover_type': 'uniform',
    'max_iteration_without_improv': None
}

# 初始化基因演算法模型
model = ga(
    function=objective_function,
    dimension=3,
    variable_type='real',
    variable_boundaries=varbound,
    algorithm_parameters=algorithm_param
)

# 執行基因演算法
model.run()

# 最佳化結果
optimal_weights = model.output_dict['variable']
mse_score = model.output_dict['function']
print(f"Optimal weights: w1 = {optimal_weights[0]:.4f}, w2 = {optimal_weights[1]:.4f}, w3 = {optimal_weights[2]:.4f}")
print(f"Final MSE score: {mse_score:.4f}")


#####################
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from scipy.optimize import minimize

# 創建測試資料
np.random.seed(42)  # 固定隨機種子以便重現
data = {
    'weight': np.random.choice(['w1', 'w2', 'w3'], size=100),  # 隨機選擇 w1, w2, w3
    'score': np.random.rand(100)  # 隨機生成 0 到 1 的分數
}

df = pd.DataFrame(data)

# One-hot 編碼 weight 欄位
df_encoded = pd.get_dummies(df['weight'], prefix='weight')
X = df_encoded.values
y = df['score'].values

# 將資料分成訓練集和測試集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 定義目標函數
# weights 是 [w1, w2, w3]
def objective_function(weights):
    train_predictions = np.dot(X_train, weights)
    test_predictions = np.dot(X_test, weights)
    
    # 多目標融合: 訓練集的 MSE + 測試集的懲罰項 (針對過度擬合)
    mse_train = mean_squared_error(y_train, train_predictions)
    mse_test_penalty = mean_squared_error(y_test, test_predictions) * 10
    
    penalty = 1000 * abs(sum(weights) - 1)  # 確保 w1 + w2 + w3 = 1
    return mse_train + mse_test_penalty + penalty  # 最小化損失

# 約束條件和邊界
def constraint(weights):
    return sum(weights) - 1

bounds = [(0, 1), (0, 1), (0, 1)]
constraints = ({'type': 'eq', 'fun': constraint})

# 初始猜測值
initial_guess = [1/3, 1/3, 1/3]

# 使用 scipy.optimize 進行最佳化
result = minimize(objective_function, initial_guess, bounds=bounds, constraints=constraints)

# 最佳化結果
if result.success:
    optimal_weights = result.x
    print(f"Optimal weights: w1 = {optimal_weights[0]:.4f}, w2 = {optimal_weights[1]:.4f}, w3 = {optimal_weights[2]:.4f}")
    print(f"Final MSE score: {result.fun:.4f}")
else:
    print("Optimization failed.")


#### 去掉outlier imporve整理排名???



import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sko.PSO import PSO
from sko.GA import GA
from sko.DE import DE
from sko.SA import SA
from sko.ACA import ACA_TSP
from sko.IA import IA_TSP
from sko.AFSA import AFSA

# 創建測試資料
np.random.seed(42)  # 固定隨機種子以便重現
data = {
    'weight': np.random.choice(['w1', 'w2', 'w3'], size=100),  # 隨機選擇 w1, w2, w3
    'score': np.random.rand(100)  # 隨機生成 0 到 1 的分數
}

df = pd.DataFrame(data)

# One-hot 編碼 weight 欄位
df_encoded = pd.get_dummies(df['weight'], prefix='weight')
X = df_encoded.values
y = df['score'].values

# 將資料分成訓練集和測試集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 定義目標函數
def objective_function(weights):
    train_predictions = np.dot(X_train, weights)
    test_predictions = np.dot(X_test, weights)
    
    # 多目標融合: 訓練集的 MSE + 測試集的懲罰項 (針對過度擬合)
    mse_train = mean_squared_error(y_train, train_predictions)
    mse_test_penalty = mean_squared_error(y_test, test_predictions) * 10
    
    penalty = 1000 * abs(sum(weights) - 1)  # 確保 w1 + w2 + w3 = 1
    return mse_train + mse_test_penalty + penalty

# 設定共享參數
bounds = [(0, 1), (0, 1), (0, 1)]
n_dim = 3  # 權重維度

# 使用粒子群演算法 (PSO)
pso = PSO(
    func=objective_function,
    n_dim=n_dim,
    pop=50,
    max_iter=200,
    lb=[0, 0, 0],
    ub=[1, 1, 1],
    w=0.8,
    c1=0.5,
    c2=0.5
)
pso.run()
pso_result = (pso.gbest_x, pso.gbest_y)

# 使用基因演算法 (GA)
ga = GA(
    func=objective_function,
    n_dim=n_dim,
    size_pop=50,
    max_iter=200,
    prob_mut=0.1,
    lb=[0, 0, 0],
    ub=[1, 1, 1]
)
ga_result = ga.run()

# 使用差分進化算法 (DE)
de = DE(
    func=objective_function,
    n_dim=n_dim,
    size_pop=50,
    max_iter=200,
    lb=[0, 0, 0],
    ub=[1, 1, 1]
)
de_result = de.run()

# 使用模擬退火算法 (SA)
sa = SA(
    func=objective_function,
    x0=np.random.rand(n_dim),
    T_max=100,
    T_min=1e-3,
    L=300,
)
sa_result = sa.run()

# 使用螞蟻演算法 (ACA_TSP)
# def aca_objective_function(weights):
#     return objective_function(weights)

# aca = ACA_TSP(func=objective_function, n_dim=n_dim,
#               size_pop=50, max_iter=200,
#               distance_matrix=None)
# #ACA_TSP(func=objective_function, n_dim=n_dim, size_pop=50, max_iter=200, distance_matrix=None)
# aca_result = aca.run()

# 使用免疫演算法 (IA_TSP)
ia = IA_TSP(func=objective_function, n_dim=n_dim, size_pop=50, max_iter=200)
ia_result = ia.run()

# 使用人工魚群演算法 (AFSA)
afsa = AFSA(func=objective_function, n_dim=n_dim, size_pop=50, max_iter=200, step=0.5, visual=1, q=0.98)
afsa_result = afsa.run()

# 比較結果
results = {
    "PSO": pso_result,
    "GA": (ga_result[0], ga_result[1]),
    "DE": (de_result[0], de_result[1]),
    "SA": (sa_result[0], sa_result[1]),
    # "ACA_TSP": (aca_result[0], aca_result[1]),
    "IA_TSP": (ia_result[0], ia_result[1]),
    "AFSA": (afsa_result[0], afsa_result[1])
}

for method, (weights, loss) in results.items():
    print(f"{method} - Optimal weights: {weights}, Final loss: {loss}")

PSO - Optimal weights: [0.60974897 0.31916312 0.07108791], Final loss: [1.27395787]
GA - Optimal weights: [0.45320591 0.42992696 0.11685914], Final loss: [1.08691804]
DE - Optimal weights: [0.28993281 0.40372215 0.30640944], Final loss: [1.15703859]
SA - Optimal weights: [-0.67517042  1.07520548  0.60031683], Final loss: 7.454552348330557
IA_TSP - Optimal weights: [2 1 0], Final loss: [2008.74147446]
AFSA - Optimal weights: [0.54140619 0.26456426 0.1939064 ], Final loss: 1.2609163089691287


#########

import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sko.PSO import PSO
from sko.GA import GA
from sko.DE import DE
from sko.SA import SA
from sko.ACA import ACA_TSP
from sko.IA import IA_TSP
from sko.AFSA import AFSA

# 創建測試資料
np.random.seed(42)  # 固定隨機種子以便重現
data = {
    'weight': np.random.choice(['w1', 'w2', 'w3'], size=1000),  # 隨機選擇 w1, w2, w3
    'score': np.random.rand(1000)  # 隨機生成 0 到 1 的分數
}

df = pd.DataFrame(data)

# One-hot 編碼 weight 欄位
df_encoded = pd.get_dummies(df['weight'], prefix='weight')
X = df_encoded.values
y = df['score'].values

# 將資料分成訓練集和測試集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 定義目標函數
# weights 是 [w1, w2, w3]
def objective_function(weights):
    predictions = np.dot(X, weights)
    penalty = 1000 * abs(sum(weights) - 1)  # 確保 w1 + w2 + w3 = 1
    return -np.sum(predictions) + penalty  # 最大化總分轉為最小化，並加入懲罰項
# 設定共享參數
bounds = [(0, 1), (0, 1), (0, 1)]
n_dim = 3  # 權重維度

# 使用粒子群演算法 (PSO)
pso = PSO(
    func=objective_function,
    n_dim=n_dim,
    pop=50,
    max_iter=200,
    lb=[0, 0, 0],
    ub=[1, 1, 1],
    w=0.8,
    c1=0.5,
    c2=0.5
)
pso.run()
pso_result = (pso.gbest_x, pso.gbest_y)

# 使用基因演算法 (GA)
ga = GA(
    func=objective_function,
    n_dim=n_dim,
    size_pop=50,
    max_iter=200,
    prob_mut=0.1,
    lb=[0, 0, 0],
    ub=[1, 1, 1]
)
ga_result = ga.run()

# 使用差分進化算法 (DE)
de = DE(
    func=objective_function,
    n_dim=n_dim,
    size_pop=50,
    max_iter=200,
    lb=[0, 0, 0],
    ub=[1, 1, 1]
)
de_result = de.run()

# 使用模擬退火算法 (SA)
sa = SA(
    func=objective_function,
    x0=np.random.rand(n_dim),
    T_max=100,
    T_min=1e-3,
    L=300,
)
sa_result = sa.run()

# 使用螞蟻演算法 (ACA_TSP)
# def aca_objective_function(weights):
#     return objective_function(weights)

# aca = ACA_TSP(func=objective_function, n_dim=n_dim,
#               size_pop=50, max_iter=200,
#               distance_matrix=None)
# #ACA_TSP(func=objective_function, n_dim=n_dim, size_pop=50, max_iter=200, distance_matrix=None)
# aca_result = aca.run()

# # 使用免疫演算法 (IA_TSP)
# ia = IA_TSP(func=objective_function, n_dim=n_dim, size_pop=50, max_iter=200)
# ia_result = ia.run()

# # 使用人工魚群演算法 (AFSA)
# afsa = AFSA(func=objective_function, n_dim=n_dim, size_pop=50, max_iter=200, step=0.5, visual=1, q=0.98)
# afsa_result = afsa.run()

# 比較結果
results = {
    "PSO": pso_result,
    "GA": (ga_result[0], ga_result[1]),
    "DE": (de_result[0], de_result[1]),
    "SA": (sa_result[0], sa_result[1]),
    # "ACA_TSP": (aca_result[0], aca_result[1]),
    # "IA_TSP": (ia_result[0], ia_result[1]),
    # "AFSA": (afsa_result[0], afsa_result[1])
}

for method, (weights, loss) in results.items():
    print(f"{method} - Optimal weights: {weights}, Final loss: {loss}")
