{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a932ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib 用于绘图\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# 处理数据的库\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "# 系统库\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "# TensorFlow的库\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05272c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62cac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# test_size 指的是划分的训练集和测试集的比例\n",
    "# test_size 默认值为0.25 表示数据分四份，测试集占一份\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(housing.data, housing.target, random_state = 7, test_size = 0.25)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all, random_state = 11, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e37bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# 训练集数据使用的是 fit_transform，和验证集与测试集中使用的 transform 是不一样的\n",
    "# fit_transform 可以计算数据的均值和方差并记录下来\n",
    "# 验证集和测试集用到的均值和方差都是训练集数据的，所以二者的归一化使用 transform 即可\n",
    "# 归一化只针对输入数据， 标签不变\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36dfebcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15480, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48f11622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c97f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数式API实现Wide & Deep model\n",
    "input = keras.layers.Input(shape=x_train.shape[1:])\n",
    "# \"\"\"\n",
    "# 函数式API就是我们可以将模型中的层结构当做函数来用\n",
    "# 如下所示就是函数式API，将input当做参数传给了hidden1\n",
    "# hidden1又当做参数传递给了hidden2\n",
    "# \"\"\"\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "# \"\"\"\n",
    "# input是wide模型的输入\n",
    "# hidden2是deep模型的输出\n",
    "# concatenate将二者拼接，并将拼接之后的结果传递给output layer\n",
    "# \"\"\"\n",
    "concat = keras.layers.concatenate([input, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "# \"\"\"\n",
    "# 固化model\n",
    "# \"\"\"\n",
    "model = keras.models.Model(inputs = [input],\n",
    "                          outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6783123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f755d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b442ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wide_deep_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              multiple                  270       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  930       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  39        \n",
      "=================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 子类API实现Wide & Deep model\n",
    "\"\"\"\n",
    "子类API就是集成父类来实现\n",
    "我们首先要定义一个Wide & Deep模型父类\n",
    "然后通过集成该父类进行模型的构建\n",
    "\"\"\"\n",
    "class WideDeepModel(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(WideDeepModel, self).__init__()\n",
    "        \"\"\"\n",
    "        定义模型的层次\n",
    "        \"\"\"\n",
    "        self.hidden1_layer = keras.layers.Dense(30, activation = 'relu')\n",
    "        self.hidden2_layer = keras.layers.Dense(30, activation = 'relu')\n",
    "        self.output_layer = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, input):\n",
    "        \"\"\"\n",
    "        完成模型的正向计算\n",
    "        \"\"\"\n",
    "        hidden1 = self.hidden1_layer(input)\n",
    "        hidden2 = self.hidden2_layer(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_layer(concat)\n",
    "        return output\n",
    "\n",
    "model = WideDeepModel()\n",
    "model.build(input_shape = (None, 8))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f0cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型， 损失函数为均方误差函数，优化函数为随机梯度下降\n",
    "model.compile(loss=\"mean_squared_error\", optimizer = keras.optimizers.SGD(0.001))\n",
    "# 回调函数使用了EarlyStopping，patience设为5， 阈值设置为1e-2\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89190276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef0b193f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b026611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.7925 - val_loss: 0.7244\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6265 - val_loss: 0.6484\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5824 - val_loss: 0.6172\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5570 - val_loss: 0.5951\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5381 - val_loss: 0.5748\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5231 - val_loss: 0.5562\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5429\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5014 - val_loss: 0.5311\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4936 - val_loss: 0.5241\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4851 - val_loss: 0.5127\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4800 - val_loss: 0.5062\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4743 - val_loss: 0.5020\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4684 - val_loss: 0.4948\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4633 - val_loss: 0.4905\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4590 - val_loss: 0.4835\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4550 - val_loss: 0.4774\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4504 - val_loss: 0.4762\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4460 - val_loss: 0.4669\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4432 - val_loss: 0.4631\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4395 - val_loss: 0.4625\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4358 - val_loss: 0.4575\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4332 - val_loss: 0.4522\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4308 - val_loss: 0.4502\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4272 - val_loss: 0.4467\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4247 - val_loss: 0.4431\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4221 - val_loss: 0.4403\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4193 - val_loss: 0.4385\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.4342\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4146 - val_loss: 0.4333TA: 0s - loss: 0.41 - ETA: 0s - loss: 0.41\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4125 - val_loss: 0.4301\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4279\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.404 - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4245\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4227\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4042 - val_loss: 0.4208\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4020 - val_loss: 0.4181\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4002 - val_loss: 0.4169\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3985 - val_loss: 0.4144\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3966 - val_loss: 0.4127\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3947 - val_loss: 0.4110\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3933 - val_loss: 0.4092\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train,\n",
    "                   validation_data=(x_valid_scaled, y_valid),\n",
    "                   epochs = 100,\n",
    "                   callbacks= callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "302f50e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41359058022499084"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9f50cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "多输入结构\n",
    "\"\"\"\n",
    "input_wide = keras.layers.Input(shape=[5]) # 前五个作为wide的输入\n",
    "input_deep = keras.layers.Input(shape=[6]) # 后六个作为deep的输入\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_deep)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_wide, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "\"\"\"\n",
    "固化model\n",
    "\"\"\"\n",
    "model = keras.models.Model(inputs = [input_wide, input_deep],\n",
    "                          outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a7bb776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 30)           210         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 30)           930         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 35)           0           input_2[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            36          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab381f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 2.1159 - val_loss: 0.8848\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7449 - val_loss: 0.7248\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.6535 - val_loss: 0.6695\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6082 - val_loss: 0.6310\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5751 - val_loss: 0.6014\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5506 - val_loss: 0.5769\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5330 - val_loss: 0.5613\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5198 - val_loss: 0.5478\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5090 - val_loss: 0.5363\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5001 - val_loss: 0.5272\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4924 - val_loss: 0.5203\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4857 - val_loss: 0.5124\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4802 - val_loss: 0.5066\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4749 - val_loss: 0.5005\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4694 - val_loss: 0.4948\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4649 - val_loss: 0.4898\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4609 - val_loss: 0.4853\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4567 - val_loss: 0.4824\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4534 - val_loss: 0.4770\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4492 - val_loss: 0.4727\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4460 - val_loss: 0.4684\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4431 - val_loss: 0.4650\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4402 - val_loss: 0.4627\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4374 - val_loss: 0.4592\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4350 - val_loss: 0.4562\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4324 - val_loss: 0.4542\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4298 - val_loss: 0.4526\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4279 - val_loss: 0.4491\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4263 - val_loss: 0.4469\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4245 - val_loss: 0.4449\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4224 - val_loss: 0.4440\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4207 - val_loss: 0.4429\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4189 - val_loss: 0.4396\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4173 - val_loss: 0.4404\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.4374\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "x_wide:数据集前5个特征\n",
    "x_deep:数据集后6个特征\n",
    "\"\"\"\n",
    "x_train_scaled_wide = x_train_scaled[:,:5]\n",
    "x_train_scaled_deep = x_train_scaled[:,2:]\n",
    "x_valid_scaled_wide = x_valid_scaled[:,:5]\n",
    "x_valid_scaled_deep = x_valid_scaled[:,2:]\n",
    "x_test_scaled_wide = x_test_scaled[:,:5]\n",
    "x_test_scaled_deep = x_test_scaled[:,2:]\n",
    "\n",
    "# 编译模型， 损失函数为均方误差函数，优化函数为随机梯度下降\n",
    "model.compile(loss=\"mean_squared_error\", optimizer = keras.optimizers.SGD(0.001))\n",
    "# 回调函数使用了EarlyStopping，patience设为5， 阈值设置为1e-2\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2)]\n",
    "\n",
    "history = model.fit([x_train_scaled_wide, x_train_scaled_deep], y_train,\n",
    "                   validation_data=([x_valid_scaled_wide, x_valid_scaled_deep], y_valid),\n",
    "                   epochs = 100,\n",
    "                   callbacks= callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb61046b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42855796217918396"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x_test_scaled_wide, x_test_scaled_deep], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0280180",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://blog.csdn.net/qq_42580947/article/details/105302840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef20538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideDeepModel(tf.keras.models.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = tf.keras.layers.Dense(30, activation='relu')\n",
    "        self.hidden2 = tf.keras.layers.Dense(30, activation='relu')\n",
    "        self.concat = tf.keras.layers.concatenate\n",
    "        self.dense = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_wide, input_deep = inputs\n",
    "        output_deep = self.hidden1(input_deep)\n",
    "        output_deep = self.hidden2(output_deep)\n",
    "        concat_input = self.concat([input_wide, output_deep])\n",
    "        output = self.dense(concat_input)\n",
    "        return output\n",
    "\n",
    "    def build_graph(self, shapes):\n",
    "        shape1, shape2 = shapes\n",
    "        input_wide = tf.keras.layers.Input(shape=shape1)\n",
    "        input_deep = tf.keras.layers.Input(shape=shape2)\n",
    "        return tf.keras.models.Model(inputs=[input_wide, input_deep], outputs=[self.call([input_wide, input_deep])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90fe1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3172189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# plot model\n",
    "tf.keras.utils.plot_model(\n",
    "    model.build_graph([(15), (15)]),\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://zhuanlan.zhihu.com/p/348968507"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
