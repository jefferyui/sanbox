import numpy as np
import pandas as pd

# 設置隨機種子
np.random.seed(42)

# 模擬數據參數
num_recipes = 5
num_machines = 10
data_points_per_machine = 100

# 正常機台數據生成
normal_data = []
for recipe in range(num_recipes):
    for machine in range(num_machines - 3):  # 正常機台
        metrics = np.random.normal(loc=0.85, scale=0.05, size=data_points_per_machine)  # 正常分佈
        for metric in metrics:
            normal_data.append([f"Recipe_{recipe}", f"Machine_{machine}", metric])



# 異常機台數據生成
anomalous_data_2 = []

for recipe in range(num_recipes):
    for machine in range(num_machines - 3, num_machines-2):  # 異常機台
        print("machine_1", machine)
        metrics = np.random.normal(loc=1, scale=0.1, size=data_points_per_machine)  # 偏移分佈
        for metric in metrics:
            anomalous_data_2.append([f"Recipe_{recipe}", f"Machine_{machine}", metric])

# # 異常機台數據生成
# anomalous_data = []
# for recipe in range(num_recipes):
#     for machine in range(num_machines - 2, num_machines):  # 異常機台
#         metrics = np.random.normal(loc=2, scale=0.1, size=data_points_per_machine)  # 偏移分佈
#         for metric in metrics:
#             anomalous_data.append([f"Recipe_{recipe}", f"Machine_{machine}", metric])


# 異常機台數據生成
anomalous_data = []

# for recipe in range(num_recipes):
#     for machine in range(num_machines - 3, num_machines-2):  # 異常機台
#         print("machine_1", machine)
#         metrics = np.random.normal(loc=1.5, scale=0.1, size=data_points_per_machine)  # 偏移分佈
#         for metric in metrics:
#             anomalous_data.append([f"Recipe_{recipe}", f"Machine_{machine}", metric])

for recipe in range(num_recipes):
    for machine in range(num_machines - 3, num_machines-2):  # 異常機台
        print("machine_1", machine)
        metrics = np.random.normal(loc=8, scale=0.1, size=data_points_per_machine)  # 偏移分佈
        for metric in metrics:
            anomalous_data.append([f"Recipe_{recipe}", f"Machine_{machine}", metric])


for recipe in range(num_recipes):
    for machine in range(num_machines - 2, num_machines-1):  # 異常機台
        print("machine_1", machine)
        metrics = np.random.normal(loc=2, scale=0.1, size=data_points_per_machine)  # 偏移分佈
        for metric in metrics:
            anomalous_data.append([f"Recipe_{recipe}", f"Machine_{machine}", metric])


# 異常機台數據生成
# anomalous_data = []
for recipe in range(num_recipes):
    for machine in range(num_machines - 1, num_machines):  # 異常機台
        print("machine_2", machine)
        metrics = np.random.normal(loc=3, scale=0.03, size=100)  # 偏移分佈 data_points_per_machine
        for metric in metrics:
            anomalous_data.append([f"Recipe_{recipe}", f"Machine_{machine}", metric])


# 合併數據
# all_data = pd.DataFrame(normal_data + anomalous_data, columns=["recipe", "machine", "metric"])
all_data = pd.DataFrame(normal_data , columns=["recipe", "machine", "metric"])
# all_data = pd.DataFrame(normal_data + anomalous_data_2, columns=["recipe", "machine", "metric"])
print(all_data.head())


from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# 將 metric 作為模型輸入
scaler = StandardScaler()
all_data['metric_scaled'] = scaler.fit_transform(all_data[['metric']])

# 準備數據
X = all_data[['metric_scaled']].values
X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout

# 增加模型結構的深度與寬度
input_dim = X.shape[1]
encoding_dim = 4  # 壓縮至 4 維

# 定義自編碼器模型
input_layer = Input(shape=(input_dim,))
encoder = Dense(32, activation="relu")(input_layer)
encoder = Dropout(0.2)(encoder)  # 加入 Dropout
encoder = Dense(encoding_dim, activation="relu")(encoder)

decoder = Dense(32, activation="relu")(encoder)
decoder = Dropout(0.2)(decoder)  # 加入 Dropout
decoder = Dense(input_dim, activation="linear")(decoder)

# 模型初始化
autoencoder = Model(inputs=input_layer, outputs=decoder)

# 添加 L1 正則化以控制模型權重
autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                    loss='mse')

# 模型訓練
history = autoencoder.fit(X_train, X_train, 
                          epochs=100, 
                          batch_size=64, 
                          shuffle=True, 
                          validation_data=(X_test, X_test),
                          verbose=1)

# 計算重建值與重建誤差
reconstructed = autoencoder.predict(X)
reconstruction_error = np.mean(np.square(X - reconstructed), axis=1)

# 將重建誤差加入數據框
all_data['reconstruction_error'] = reconstruction_error

import seaborn as sns
# import matplotlib.pyplot as plt

# # 繪製重建誤差分佈
# sns.boxplot(data=all_data, x='machine', y='reconstruction_error')
# plt.xticks(rotation=45)
# plt.title("Reconstruction Error by Machine")
# plt.show()

# # 篩選異常機台
# threshold = np.percentile(reconstruction_error, 95)  # 設定異常閾值  # 用下面判較容易
# # 占比個別群體比
# # threshold = 0.02
# all_data['is_anomalous'] = all_data['reconstruction_error'] > threshold

# ####  HL < 3成 ---> all easy

# # 查看異常機台分佈
# anomalous_machines = all_data[all_data['is_anomalous']]['machine'].unique()
# print("異常機台:", anomalous_machines)

all_data['reconstruction_error'] = reconstruction_error
# # 計算中位數和 MAD
median_error = np.median(all_data['reconstruction_error'])
mad_error = np.median(np.abs(all_data['reconstruction_error'] - median_error))

# # 設定敏感度參數 k
# k = 5  # 可調整
all_data['outlier_score'] = np.abs(all_data['reconstruction_error'] - median_error) / mad_error

k = 100   # Error建的會恨明顯好判

# 標記離群點
all_data['is_anomalous'] = all_data['outlier_score'] > k

# 查看異常機台分佈
anomalous_machines = all_data[all_data['is_anomalous']]['machine'].unique()
print("異常機台:", anomalous_machines)

sns.boxplot(data=all_data, x='machine', y='outlier_score')
plt.xticks(rotation=45)
plt.title("Reconstruction Error by Machine")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

sns.histplot(all_data['outlier_score'], bins=50, kde=True)
plt.axvline(x=k, color='r', linestyle='--', label=f'Outlier Threshold (k={k})')
plt.title('Outlier Score Distribution')
plt.legend()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# 可視化修正後的分數分佈
sns.histplot(all_data['metric'], bins=50, kde=True)
plt.title('Metric Distribution')
plt.show()

# 檢查異常數據
print("異常數據樣本:")
print(all_data[all_data['is_anomalous']].head())
